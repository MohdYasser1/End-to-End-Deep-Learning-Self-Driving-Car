{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohdYasser1/End-to-End-Deep-Learning-Self-Driving-Car/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2urExHJ7vHHa"
      },
      "source": [
        "# Behaviour Clonning for Self-Driving Car simulator using Deep Learning  \n",
        "This NoteBook is about using deep-learning to take images captured by a simulator that is driven by myself. The goal of this project is to try several famous deep-learning architecture as well as trying one by self.\n",
        "### The content of this NoteBook will include:\n",
        "1. Self-Made architecture\n",
        "2. Nvidea's architecture for Self-Driving cars (Comming Soon ...)\n",
        "3. An upgrade for the Nvidea's architecture using Feature Analysis and Selection (Comming Soon ...)\n",
        "4. End-to-End Learning with Memory Models (Comming Soon ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzS-yOjHvLhC"
      },
      "source": [
        "### 1. Self-Made Architecture  \n",
        "We will first start with an architecture made from my knowledge of CNN and using random hyperparamters and random layers (Everything will be random ðŸ˜‚). This architecture will be the base architecture to evaluate the next famous architectures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "5FRQCkoKvBRR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b7a785b-66c0-4c1c-96d3-7e60acc84085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_PMIvgULvNaD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c927e2ac-47f3-44b0-9997-3a716fb5117f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Import Numpy for data manuplation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Import Pytorch\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, ConcatDataset, random_split, DataLoader\n",
        "\n",
        "# Import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "#Import PIL.Image\n",
        "from PIL import Image\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYLrxGEpxbnX"
      },
      "source": [
        "The Data collected are seperated into 2 Dataset:  \n",
        "1. A dataset driving the track normally.\n",
        "2. A dataset driving the track the other way"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7ZfTl7uxgMs"
      },
      "source": [
        "We first need to make a custom Dataset to get the images with the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "EQIOm4tSvPd8"
      },
      "outputs": [],
      "source": [
        "class CustomDataSet(Dataset):\n",
        "    def __init__(self, csv_file, transform = None):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        images = Image.open(self.df.iloc[idx, 0])\n",
        "\n",
        "        if self.transform:\n",
        "            images =self.transform(images)\n",
        "\n",
        "        steering_angle = self.df.iloc[idx, 3:4].values.astype(float)\n",
        "        throttle = self.df.iloc[idx, 4:5].values.astype(float)\n",
        "\n",
        "        return images, steering_angle, throttle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "BgVF6u90x_j_"
      },
      "outputs": [],
      "source": [
        "# Inputting image details\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 160, 320, 3\n",
        "INPUT_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
        "\n",
        "#Defining image transformations\n",
        "data_transform = transforms.Compose([transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH)),\n",
        "                                    transforms.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQu1pz81yCI8",
        "outputId": "c01d9c42-0ffb-49d8-e9bf-da35e29d4ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of the whole datase: 6633\n",
            "\n",
            "The size of the train data: 5306\n",
            "The size of the test data: 1327\n"
          ]
        }
      ],
      "source": [
        "# Loading csvs files\n",
        "forward_csv_path = r\"/content/drive/MyDrive/Data/RacingTeam/DeepLearning Project/Forward/driving_log.csv\"\n",
        "backward_csv_path = r\"/content/drive/MyDrive/Data/RacingTeam/DeepLearning Project/Backward/driving_log.csv\"\n",
        "\n",
        "# Create the DataSets\n",
        "froward_data = CustomDataSet(forward_csv_path, data_transform)\n",
        "backward_data = CustomDataSet(backward_csv_path, data_transform)\n",
        "\n",
        "# Joining the 2 Datasets\n",
        "data = ConcatDataset([froward_data, backward_data])\n",
        "\n",
        "#Checking the data\n",
        "print(f\"The size of the whole datase: {len(data)}\\n\")\n",
        "\n",
        "# Splitting the data into train and test\n",
        "train_size = int(0.8 * len(data))\n",
        "test_size = len(data) - train_size\n",
        "train_data, test_data = random_split(data, [train_size, test_size])\n",
        "print(f\"The size of the train data: {len(train_data)}\")\n",
        "print(f\"The size of the test data: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Ugg6BQL8yXlP"
      },
      "outputs": [],
      "source": [
        "# Creating the DataLoaders\n",
        "train_loader = DataLoader(train_data, batch_size = 40, shuffle = True)\n",
        "test_loader = DataLoader(test_data, batch_size = 40, shuffle = False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxdCasCFycmG"
      },
      "source": [
        "This architecture will be based on a simple architecture I took in the Deep Learning Session.  \n",
        "The Architecture will be consisted of:\n",
        "1. Convlution Layer 48@78x158 + Maxpooling 48@39x79\n",
        "2. Convlution Layer 96@18x38 + Maxpooling 96@9x19\n",
        "3. Flatten\n",
        "4. Fully-connected layer with 50 neuros\n",
        "5. Fully-connected layer with 10 neurons\n",
        "6. Output-Layer with 2 outputs: Steering_angle & Throttle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "zMgUhgSNyf-b"
      },
      "outputs": [],
      "source": [
        "# Creating the CNN model\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SelfMadeModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SelfMadeModel, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=3,\n",
        "                out_channels=48,\n",
        "                kernel_size=5,\n",
        "                stride=(2,2),\n",
        "            ),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(48, 96, 5, (2,2)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "        )\n",
        "        self.fc = nn.Linear(9*19*96, 25)\n",
        "        self.fc1 = nn.Linear(25, 5)\n",
        "        self.fc2 = nn.Linear(5, 2)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(-1, 16416)\n",
        "        x = F.relu(self.fc(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "lJX_lff5ylJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e693ec83-455b-40c8-be51-f46a5842c1ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelfMadeModel(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(3, 48, kernel_size=(5, 5), stride=(2, 2))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(48, 96, kernel_size=(5, 5), stride=(2, 2))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=16416, out_features=25, bias=True)\n",
              "  (fc1): Linear(in_features=25, out_features=5, bias=True)\n",
              "  (fc2): Linear(in_features=5, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "model = SelfMadeModel().to(device)\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.005)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "koYeVacBy_7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bb06ca5-1c66-41a2-abfa-5c72e6eefa12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 160, 320])\n",
            "tensor([[-0.1628, -0.0431]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "tensor(0.6009, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ],
      "source": [
        "# Trying the model\n",
        "examples = iter(test_loader)\n",
        "example_data = next(examples)\n",
        "images = example_data[0][0].to(device)\n",
        "dummy_input = torch.randn(3, 160, 320).to(device)\n",
        "print(dummy_input.shape)\n",
        "output = model(dummy_input)\n",
        "print(output)\n",
        "loss = loss_fn(output, torch.tensor((-0.5, 1.0)).to(device))\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "oU8zqj3rzCz6"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "def train(num_epoches, model, loss_fn, optimizer, loader):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    total_step = len(loader)\n",
        "\n",
        "    for epochs in range(num_epoches):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, (images, steering_angle, throttle) in enumerate (loader):\n",
        "\n",
        "            images = images.to(device)\n",
        "            steering_angle = steering_angle.to(device)\n",
        "            throttle = throttle.to(device)\n",
        "\n",
        "\n",
        "            outputs = model(images)\n",
        "#             print(outputs)\n",
        "#             print([steering_angle, throttle])\n",
        "            loss = loss_fn(outputs, torch.cat((steering_angle, throttle), dim=1).to(torch.float32))\n",
        "\n",
        "#             print(output.dtype)\n",
        "#             print(torch.cat((steering_angle, throttle), dim=1).to(torch.float32).dtype)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'[{epochs + 1}] loss: {running_loss / total_step:.3f}')\n",
        "    print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Q_9-8yjfSrt-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f03917b2-6abc-4a9e-d6ca-c9e58335caa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] loss: 0.588\n",
            "[2] loss: 0.028\n",
            "[3] loss: 0.027\n",
            "[4] loss: 0.027\n",
            "[5] loss: 0.026\n",
            "[6] loss: 0.026\n",
            "[7] loss: 0.025\n",
            "[8] loss: 0.025\n",
            "[9] loss: 0.024\n",
            "[10] loss: 0.022\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(10 , model, loss_fn, optimizer, train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "SYsuJczwPdin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e14d6494-b89a-4466-9c21-f42339dfb625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34 / 34\n",
            "0.026414296535008094\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "\n",
        "running_loss = 0.0\n",
        "num_of_batches = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "  n_samples = len(test_loader.dataset)\n",
        "\n",
        "  for i, (images, steering_angle, throttle) in enumerate (test_loader):\n",
        "\n",
        "    images = images.to(device)\n",
        "    steering_angle = steering_angle.to(device)\n",
        "    throttle = throttle.to(device)\n",
        "\n",
        "    preds = model(images)\n",
        "    loss = loss_fn(preds, torch.cat((steering_angle, throttle), dim=1).to(torch.float32))\n",
        "    running_loss += loss.item()\n",
        "    num_of_batches +=1\n",
        "    clear_output(wait=True)\n",
        "    print(f'{i+1} / {len(test_loader)}')\n",
        "print(running_loss/num_of_batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "fsOZ12Wvpkh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b089bccb-3d41-4605-ad52-e34353bc205b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[ 0.1312,  1.0033],\n",
            "        [ 0.0257,  0.9975],\n",
            "        [ 0.0129,  1.0196],\n",
            "        [ 0.0246,  1.0465],\n",
            "        [ 0.0620,  1.0475],\n",
            "        [-0.0583,  1.0413],\n",
            "        [-0.1045,  0.9877]], device='cuda:0'), tensor([[0.3500, 1.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [0.0000, 1.0000]], device='cuda:0')]\n"
          ]
        }
      ],
      "source": [
        "print([preds, torch.cat((steering_angle, throttle), dim=1).to(torch.float32)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "zTNp5hr43syb"
      },
      "outputs": [],
      "source": [
        "torch.save(model, \"model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "9ZSfYdtFJC6r"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "steer=[]\n",
        "\n",
        "for _,y,_ in train_loader:\n",
        "  for k in range(len(y)):\n",
        "    steer.append(y[k])\n",
        "# plt.hist(np.array(steer), density = True, weights=np.ones(len(steer)) / len(steer) * 100)\n",
        "# plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "_AnWL3-ZJFH4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "054ef24e-7b03-46de-cfa7-e99a4d55775a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-64-6023729e997e>:1: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  np.count_nonzero(np.array(steer) == 0)/len(steer)\n",
            "<ipython-input-64-6023729e997e>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  np.count_nonzero(np.array(steer) == 0)/len(steer)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8077647945721824"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "np.count_nonzero(np.array(steer) == 0)/len(steer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steer = [tensor.item() for tensor in steer]\n",
        "\n",
        "plt.hist(np.array(steer))\n",
        "plt.show\n"
      ],
      "metadata": {
        "id": "pmtJP1SNUNUT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "31291e2e-42ec-4f7d-b090-d26d79ded6f9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yISws3XTJIrO"
      },
      "source": [
        "Almost 80% of the train data has a steering angle of 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83aMkRAsN7cp"
      },
      "source": [
        "We will try to fix it by getting only 25% of the data that has a value of 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "32OR6uEOJ_PI"
      },
      "outputs": [],
      "source": [
        "zero_angle_data = [sample for sample in train_loader.dataset if sample[1][0] == 0]\n",
        "non_zero_angle_data = [sample for sample in train_loader.dataset if sample[1][0] != 0]\n",
        "sample_size = int(0.25 * len(zero_angle_data))\n",
        "sampled_data = torch.utils.data.RandomSampler(zero_angle_data, num_samples=sample_size)\n",
        "\n",
        "#Create a dataset from the random sampler\n",
        "sampled_indices = list(sampled_data)\n",
        "sampled_dataset = [train_loader.dataset[i] for i in sampled_indices]\n",
        "\n",
        "processed_train = ConcatDataset([sampled_dataset, non_zero_angle_data])\n",
        "new_train_loader = DataLoader(processed_train, batch_size=40, shuffle=True)\n",
        "# len(new_train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "IDCGjvNfPAEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "086a1db2-3d43-41f6-bf15-cb45d30f1828"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2091"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "len(new_train_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "4HE4WmxLPCVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "614840db-5040-4dad-d622-defcd803d3fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-68-1af6d36fd842>:8: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  np.count_nonzero(np.array(steer) == 0)/len(steer)\n",
            "<ipython-input-68-1af6d36fd842>:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  np.count_nonzero(np.array(steer) == 0)/len(steer)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4146341463414634"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "steer=[]\n",
        "\n",
        "for _,y,_ in new_train_loader:\n",
        "  for k in range(len(y)):\n",
        "    steer.append(y[k])\n",
        "# plt.hist(np.array(steer), density = True, weights=np.ones(len(steer)) / len(steer) * 100)\n",
        "# plt.show\n",
        "np.count_nonzero(np.array(steer) == 0)/len(steer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steer = [tensor.item() for tensor in steer]\n",
        "\n",
        "plt.hist(np.array(steer))\n",
        "plt.show\n"
      ],
      "metadata": {
        "id": "b-1pWplEUZRn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "499ea8b7-9372-43c6-e285-344151e595fd"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzQk8EbCSjWx",
        "outputId": "7b5546e9-e75b-4311-f903-fad8d8a95f9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] loss: 0.066\n",
            "[2] loss: 0.066\n",
            "[3] loss: 0.066\n",
            "[4] loss: 0.067\n",
            "[5] loss: 0.066\n",
            "[6] loss: 0.066\n",
            "[7] loss: 0.068\n",
            "[8] loss: 0.067\n",
            "[9] loss: 0.066\n",
            "[10] loss: 0.068\n",
            "[11] loss: 0.067\n",
            "[12] loss: 0.067\n",
            "[13] loss: 0.067\n",
            "[14] loss: 0.067\n",
            "[15] loss: 0.066\n",
            "[16] loss: 0.068\n",
            "[17] loss: 0.066\n",
            "[18] loss: 0.066\n",
            "[19] loss: 0.066\n",
            "[20] loss: 0.066\n",
            "[21] loss: 0.067\n",
            "[22] loss: 0.067\n",
            "[23] loss: 0.067\n",
            "[24] loss: 0.066\n",
            "[25] loss: 0.066\n",
            "[26] loss: 0.067\n",
            "[27] loss: 0.067\n",
            "[28] loss: 0.067\n",
            "[29] loss: 0.066\n",
            "[30] loss: 0.067\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(30 , model, loss_fn, optimizer, new_train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m--x6wFTS-hs",
        "outputId": "ad6d4a9f-3de4-42cb-c814-6f299fc5e6d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34 / 34\n",
            "0.03191089942393934\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "\n",
        "running_loss = 0.0\n",
        "num_of_batches = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "  n_samples = len(test_loader.dataset)\n",
        "\n",
        "  for i, (images, steering_angle, throttle) in enumerate (test_loader):\n",
        "\n",
        "    images = images.to(device)\n",
        "    steering_angle = steering_angle.to(device)\n",
        "    throttle = throttle.to(device)\n",
        "\n",
        "    preds = model(images)\n",
        "    loss = loss_fn(preds, torch.cat((steering_angle, throttle), dim=1).to(torch.float32))\n",
        "    running_loss += loss.item()\n",
        "    num_of_batches +=1\n",
        "    clear_output(wait=True)\n",
        "    print(f'{i+1} / {len(test_loader)}')\n",
        "print(running_loss/num_of_batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbKvxVWGTTHb",
        "outputId": "13777dbd-1d93-425f-96f0-ccac1188ae5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[0.0091, 0.9528],\n",
            "        [0.0091, 0.9528],\n",
            "        [0.0091, 0.9528],\n",
            "        [0.0091, 0.9528],\n",
            "        [0.0091, 0.9528],\n",
            "        [0.0091, 0.9528],\n",
            "        [0.0091, 0.9528]], device='cuda:0'), tensor([[ 0.2500,  1.0000],\n",
            "        [ 0.0000,  1.0000],\n",
            "        [ 0.0000,  1.0000],\n",
            "        [ 0.0500,  1.0000],\n",
            "        [ 0.0000,  1.0000],\n",
            "        [ 0.0000,  1.0000],\n",
            "        [-0.7000,  1.0000]], device='cuda:0')]\n"
          ]
        }
      ],
      "source": [
        "#Check the data\n",
        "print([preds, torch.cat((steering_angle, throttle), dim=1).to(torch.float32)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "8ulZ-uV5Vamk"
      },
      "outputs": [],
      "source": [
        "torch.save(model, \"model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAGcgrIxVLNN"
      },
      "source": [
        "The model began to variate but it stills not that significant. My initial guess is that it needs some normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_l_SOAIOJ1S"
      },
      "source": [
        "### 2. Nvidea's architecture for Self-Driving cars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2K08lW_OTh7"
      },
      "source": [
        "This model's architecture will be based on Nvidea's paper on self-driving cars withe the title \"End to End Learning for Self-Driving Cars\".\n",
        "Nvideia's Paper:https://arxiv.org/pdf/1604.07316v1.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FczDHIlypH9s"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "#We will create a dataset to apply some transformation and agumentations specified in the paper\n",
        "\n",
        "def crop(image):\n",
        "    \"\"\"\n",
        "    Crop the image (removing the sky at the top and the car front at the bottom)\n",
        "    \"\"\"\n",
        "    return image[60:-25, :, :] # remove the sky and the car front\n",
        "\n",
        "def resize(image):\n",
        "    \"\"\"\n",
        "    Resize the image to the input shape used by the network model\n",
        "    \"\"\"\n",
        "    return cv2.resize(image, (66, 200), cv2.INTER_AREA)\n",
        "\n",
        "def rgb2yuv(image):\n",
        "    \"\"\"\n",
        "    Convert the image from RGB to YUV (This is what the NVIDIA model does)\n",
        "    \"\"\"\n",
        "    return cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
        "\n",
        "def preprocess(image):\n",
        "    \"\"\"\n",
        "    Combine all preprocess functions into one\n",
        "    \"\"\"\n",
        "    image = crop(image)\n",
        "    image = resize(image)\n",
        "    image = rgb2yuv(image)\n",
        "    return image\n",
        "\n",
        "def random_brightness(image):\n",
        "    \"\"\"\n",
        "    Randomly adjust brightness of the image.\n",
        "    \"\"\"\n",
        "    # HSV (Hue, Saturation, Value) is also called HSB ('B' for Brightness).\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "    ratio = 1.0 + 0.4 * (np.random.rand() - 0.5)\n",
        "    hsv[:,:,2] =  hsv[:,:,2] * ratio\n",
        "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
        "\n",
        "def random_shadow(image):\n",
        "    \"\"\"\n",
        "    Generates and adds random shadow\n",
        "    \"\"\"\n",
        "    # (x1, y1) and (x2, y2) forms a line\n",
        "    # xm, ym gives all the locations of the image\n",
        "    x1, y1 = 200 * np.random.rand(), 0\n",
        "    x2, y2 = 200 * np.random.rand(), 66\n",
        "    xm, ym = np.mgrid[0:66, 0:200]\n",
        "\n",
        "    # mathematically speaking, we want to set 1 below the line and zero otherwise\n",
        "    # Our coordinate is up side down.  So, the above the line:\n",
        "    # (ym-y1)/(xm-x1) > (y2-y1)/(x2-x1)\n",
        "    # as x2 == x1 causes zero-division problem, we'll write it in the below form:\n",
        "    # (ym-y1)*(x2-x1) - (y2-y1)*(xm-x1) > 0\n",
        "    mask = np.zeros_like(image[:, :, 1])\n",
        "    mask[(ym - y1) * (x2 - x1) - (y2 - y1) * (xm - x1) > 0] = 1\n",
        "\n",
        "    # choose which side should have shadow and adjust saturation\n",
        "    cond = mask == np.random.randint(2)\n",
        "    s_ratio = np.random.uniform(low=0.2, high=0.5)\n",
        "\n",
        "    # adjust Saturation in HLS(Hue, Light, Saturation)\n",
        "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
        "    hls[:, :, 1][cond] = hls[:, :, 1][cond] * s_ratio\n",
        "    return cv2.cvtColor(hls, cv2.COLOR_HLS2RGB)\n",
        "\n",
        "\n",
        "def random_translate(image, steering_angle, range_x = 100, range_y = 10):\n",
        "  \"\"\"\n",
        "  Randomly shift the image virtially and horizontally (translation).\n",
        "  \"\"\"\n",
        "  trans_x = range_x * (np.random.rand() - 0.5)\n",
        "  trans_y = range_y * (np.random.rand() - 0.5)\n",
        "  steering_angle += trans_x * 0.002\n",
        "  trans_m = np.float32([[1, 0, trans_x], [0, 1, trans_y]])\n",
        "  height, width = image.shape[:2]\n",
        "  image = cv2.warpAffine(image, trans_m, (width, height))\n",
        "  return image, steering_angle\n",
        "\n",
        "\n",
        "def random_flip(image, steering_angle):\n",
        "  \"\"\"\n",
        "  Randomly flipt the image left <-> right, and adjust the steering angle.\n",
        "  \"\"\"\n",
        "  if np.random.rand() < 0.5:\n",
        "    image = cv2.flip(image, 1)\n",
        "    steering_angle = -steering_angle\n",
        "    return image, steering_angle\n",
        "\n",
        "def augment(image, steering_angle):\n",
        "  \"\"\"\n",
        "  Generate an augumented image and adjust steering angle.\n",
        "  \"\"\"\n",
        "  image, steering_angle = random_flip(image, steering_angle)\n",
        "  image, steering_angle = random_translate(image, steering_angle)\n",
        "  image = random_shadow(image)\n",
        "  image = random_brightness(image)\n",
        "\n",
        "  return image, steering_angle\n",
        "\n",
        "class NvideaDataset(Dataset):\n",
        "    def __init__(self, image, steering_angle, throttle, transform, is_training):\n",
        "        self.image = image\n",
        "        self.steering_angle = steering_angle\n",
        "        self.throttle = throttle\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.steering_angle)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        images = self.image[idx]\n",
        "        steering_angle = self.steering_angle[idx]\n",
        "        throttle = self.throttle[idx]\n",
        "\n",
        "        if is_training and np.random.rand() < 0.6:\n",
        "          images, steering_angle = augument(images, steering_angle)\n",
        "\n",
        "        if self.transform:\n",
        "            images =self.transform(images)\n",
        "\n",
        "        return images, steering_angle, throttle\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "oQZ82Z8d4V5S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a36f20-86c6-4ba5-f66c-e39a3568ea0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of the whole datase: 6633\n",
            "\n",
            "The size of the train data: 5306\n",
            "The size of the test data: 1327\n"
          ]
        }
      ],
      "source": [
        "data_transform = transforms.Compose([transforms.Resize((66,200)),\n",
        "                                     transforms.ToTensor()])\n",
        "\n",
        "# Loading csvs files\n",
        "forward_csv_path = r\"/content/drive/MyDrive/Data/RacingTeam/DeepLearning Project/Forward/driving_log.csv\"\n",
        "backward_csv_path = r\"/content/drive/MyDrive/Data/RacingTeam/DeepLearning Project/Backward/driving_log.csv\"\n",
        "\n",
        "# Create the DataSets\n",
        "froward_data = CustomDataSet(forward_csv_path, data_transform)\n",
        "backward_data = CustomDataSet(backward_csv_path, data_transform)\n",
        "\n",
        "# Joining the 2 Datasets\n",
        "data = ConcatDataset([froward_data, backward_data])\n",
        "\n",
        "#Checking the data\n",
        "print(f\"The size of the whole datase: {len(data)}\\n\")\n",
        "\n",
        "# Splitting the data into train and test\n",
        "train_size = int(0.8 * len(data))\n",
        "test_size = len(data) - train_size\n",
        "train_data, test_data = random_split(data, [train_size, test_size])\n",
        "\n",
        "# train_img = [item[0] for item in train_data]\n",
        "# train_steer = [item[1] for item in train_data]\n",
        "# train_thrtl = [item[2] for item in train_data]\n",
        "\n",
        "# test_img = [item[0] for item in test_data]\n",
        "# test_steer = [item[1] for item in test_data]\n",
        "# test_thrtl = [item[2] for item in test_data]\n",
        "\n",
        "# train_data = NvideaDataset(train_img, train_steer, train_thrtl,data_transform, True)\n",
        "# test_data = NvideaDataset(test_img, test_steer, test_thrtl,data_transform False)\n",
        "\n",
        "print(f\"The size of the train data: {len(train_data)}\")\n",
        "print(f\"The size of the test data: {len(test_data)}\")\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=40, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=40, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljGtURRRdJFd"
      },
      "source": [
        "The architecture will consist of:\n",
        "1. Normalized input planes 3@66x200\n",
        "2. Convulution feature map 5x5, 24@31x98\n",
        "3. Convulution feature map 5x5, 36@14x47\n",
        "4. Convulution feature map 5x5. 48@5x22\n",
        "5. Convulution feature map 3x3. 64@3x20\n",
        "6. Convulution feature map 3x3, 64@1x18\n",
        "7. Flatten\n",
        "8. Fully-Connected layer with 1164 neurons\n",
        "9. Fully-Connected layer with 100 neurons\n",
        "10. Fully-Connected layer with 50 neurons\n",
        "11. Fully-Connected layer with 10 neurons\n",
        "12. Output layer with 2 neurons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxsXLLTlf2zs"
      },
      "source": [
        "As we can see this architecture is more complex than the self-made architecture and more scientificaly based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "pGG6m34FOH78"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class NvideaModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NvideaModel, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "      nn.Conv2d(3, 24, 5, (2,2)),\n",
        "      nn.ELU(),\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "      nn.Conv2d(24, 36, 5, (2,2)),\n",
        "      nn.ELU(),\n",
        "    )\n",
        "    self.conv3 = nn.Sequential(\n",
        "      nn.Conv2d(36, 48, 5, (2,2)),\n",
        "      nn.ELU(),\n",
        "    )\n",
        "    self.conv4 = nn.Sequential(\n",
        "      nn.Conv2d(48, 64, 3),\n",
        "      nn.ELU(),\n",
        "    )\n",
        "    self.conv5 = nn.Sequential(\n",
        "      nn.Conv2d(64, 64, 3),\n",
        "      nn.ELU(),\n",
        "    )\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "    self.fc = nn.Linear(64 * 1 * 18, 100)\n",
        "    self.fc1 = nn.Linear(100, 50)\n",
        "    self.fc2 = nn.Linear(50, 10)\n",
        "    self.fc3 = nn.Linear(10, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.conv5(x)\n",
        "    x = self.dropout(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = F.elu(self.fc(x))\n",
        "    x = F.elu(self.fc1(x))\n",
        "    x = F.elu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "dsnTnkyy5ctu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a183926-c8ac-4509-a26c-4cac003cadf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NvideaModel(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(3, 24, kernel_size=(5, 5), stride=(2, 2))\n",
              "    (1): ELU(alpha=1.0)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(24, 36, kernel_size=(5, 5), stride=(2, 2))\n",
              "    (1): ELU(alpha=1.0)\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv2d(36, 48, kernel_size=(5, 5), stride=(2, 2))\n",
              "    (1): ELU(alpha=1.0)\n",
              "  )\n",
              "  (conv4): Sequential(\n",
              "    (0): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ELU(alpha=1.0)\n",
              "  )\n",
              "  (conv5): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ELU(alpha=1.0)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=1152, out_features=100, bias=True)\n",
              "  (fc1): Linear(in_features=100, out_features=50, bias=True)\n",
              "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
              "  (fc3): Linear(in_features=10, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "modelN = NvideaModel().to(device)\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.Adam(modelN.parameters(), lr = 0.01)\n",
        "modelN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXFXFLFmOjVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1680702f-18b3-4ba5-f57a-b6a2888a28a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] loss: 98.820\n",
            "[2] loss: 0.311\n",
            "[3] loss: 0.104\n",
            "[4] loss: 0.043\n",
            "[5] loss: 0.031\n",
            "[6] loss: 0.030\n",
            "[7] loss: 0.030\n",
            "[8] loss: 0.030\n",
            "[9] loss: 0.030\n",
            "[10] loss: 0.030\n",
            "[11] loss: 0.030\n"
          ]
        }
      ],
      "source": [
        "train(20, modelN, loss_fn, optimizer, train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "\n",
        "running_loss = 0.0\n",
        "num_of_batches = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "  n_samples = len(test_loader.dataset)\n",
        "\n",
        "  for i, (images, steering_angle, throttle) in enumerate (test_loader):\n",
        "\n",
        "    images = images.to(device)\n",
        "    steering_angle = steering_angle.to(device)\n",
        "    throttle = throttle.to(device)\n",
        "\n",
        "    preds = modelN(images)\n",
        "    loss = loss_fn(preds, torch.cat((steering_angle, throttle), dim=1).to(torch.float32))\n",
        "    running_loss += loss.item()\n",
        "    num_of_batches +=1\n",
        "    clear_output(wait=True)\n",
        "    print(f'{i+1} / {len(test_loader)}')\n",
        "print(running_loss/num_of_batches)"
      ],
      "metadata": {
        "id": "kedZgZLqW_eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "46acVb9Vyebu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1rtBYsuxM2DWE0YWi9Rm57d3wR8cWea2q",
      "authorship_tag": "ABX9TyMWCvIrG4UTfV0Trt4MZgIb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}